{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Handling Categorical Data"
      ],
      "metadata": {
        "id": "w-zTW7oIyoPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding Nominal Categorical Features"
      ],
      "metadata": {
        "id": "1mH6gtFLyqph"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsIDwgr6vg0H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Load the csv file into a pandas DataFrame\n",
        "df = pd.read_csv('Prakriti_With_Features.csv')\n",
        "\n",
        "# Select the 'Complexion' column as our feature\n",
        "feature = df[['Complexion']].values\n",
        "\n",
        "# Create a one-hot encoder\n",
        "one_hot_encoder = LabelBinarizer()\n",
        "\n",
        "# Fit the encoder and transform the feature\n",
        "one_hot_encoded = one_hot_encoder.fit_transform(feature)\n",
        "\n",
        "print(\"One-hot encoded 'Complexion' feature (first 5 rows):\")\n",
        "print(one_hot_encoded[:5])\n",
        "\n",
        "# View the classes that were encoded\n",
        "print(\"\\nEncoded classes:\")\n",
        "print(one_hot_encoder.classes_)\n",
        "\n",
        "# We can also reverse the transformation\n",
        "print(\"\\nReversed one-hot encoding (first 5 rows):\")\n",
        "print(one_hot_encoder.inverse_transform(one_hot_encoded)[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_dummies"
      ],
      "metadata": {
        "id": "wWaKPBXZyvXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the DataFrame for this operation\n",
        "df_dummies = df.copy()\n",
        "\n",
        "# Apply get_dummies to the 'Complexion' column\n",
        "complexion_dummies = pd.get_dummies(df_dummies['Complexion'], prefix='Complexion')\n",
        "\n",
        "# Join the new columns to the original DataFrame\n",
        "df_dummies = pd.concat([df_dummies, complexion_dummies], axis=1)\n",
        "\n",
        "print(\"DataFrame with one-hot encoded 'Complexion' using get_dummies (first 5 rows):\")\n",
        "print(df_dummies[['Complexion', 'Complexion_Dark-Complexion, tans easily', 'Complexion_Fair-skin sunburns easily', 'Complexion_White, pale, tans easily']].head())"
      ],
      "metadata": {
        "id": "qwI4DswpwC2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding Ordinal Categorical Features"
      ],
      "metadata": {
        "id": "5U0f_Upby0e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the DataFrame for this operation\n",
        "df_ordinal = df.copy()\n",
        "\n",
        "# Create a mapping dictionary for the ordered categories\n",
        "stress_mapper = {'low': 1, 'moderate': 2, 'high': 3}\n",
        "\n",
        "# Apply the mapping to the 'Stress Levels' column\n",
        "df_ordinal['Stress Levels_encoded'] = df_ordinal['Stress Levels'].replace(stress_mapper)\n",
        "\n",
        "print(\"Original and encoded 'Stress Levels' data (showing a mix of values):\")\n",
        "print(df_ordinal[['Stress Levels', 'Stress Levels_encoded']].sample(5, random_state=42))"
      ],
      "metadata": {
        "id": "btrTgy10wINP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding Dictionaries of Features"
      ],
      "metadata": {
        "id": "7CY15thiy5yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# Example data as a list of dictionaries\n",
        "data_dict = [{'Red': 2, 'Blue': 4},\n",
        "             {'Red': 4, 'Blue': 3},\n",
        "             {'Red': 1, 'Yellow': 2},\n",
        "             {'Red': 2, 'Yellow': 2}]\n",
        "\n",
        "# Create a DictVectorizer instance\n",
        "dictvectorizer = DictVectorizer(sparse=False)\n",
        "\n",
        "# Convert the dictionary to a feature matrix\n",
        "features = dictvectorizer.fit_transform(data_dict)\n",
        "\n",
        "print(\"Feature matrix from dictionary:\")\n",
        "print(features)\n",
        "\n",
        "# Get the feature names\n",
        "print(\"\\nFeature names:\")\n",
        "print(dictvectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "g0xZI4-PwLSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imputing Missing Class Values"
      ],
      "metadata": {
        "id": "F5AHbe6hzNjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the csv file\n",
        "df = pd.read_csv('Prakriti_With_Features.csv')\n",
        "\n",
        "# Create a copy and introduce a missing value\n",
        "df_impute_cat = df.copy()\n",
        "df_impute_cat.loc[1, 'Hair Color'] = np.nan\n",
        "df_impute_cat.loc[5, 'Hair Color'] = np.nan\n",
        "\n",
        "# Create an imputer to replace missing values with the most frequent category\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# --- CORRECTED LINE ---\n",
        "# Reshape data, apply the transformation, and flatten the result to 1D\n",
        "df_impute_cat['Hair Color_imputed'] = imputer_cat.fit_transform(df_impute_cat[['Hair Color']]).ravel()\n",
        "\n",
        "print(\"DataFrame after imputing 'Hair Color' (rows 0-6):\")\n",
        "print(df_impute_cat[['Hair Color', 'Hair Color_imputed']].head(7))"
      ],
      "metadata": {
        "id": "R0hL6CuZwTZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Imbalanced Classes"
      ],
      "metadata": {
        "id": "eLoFAZBJzSmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Distribution of classes in the 'Dosha' column:\")\n",
        "print(df['Dosha'].value_counts())"
      ],
      "metadata": {
        "id": "S6XyxLVawcQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Using class_weight='balanced' automatically adjusts weights\n",
        "# inversely proportional to class frequencies\n",
        "balanced_rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "print(\"Random Forest Classifier with balanced class weights:\")\n",
        "print(balanced_rf)\n",
        "\n",
        "# You can also manually set weights\n",
        "# Note: I've updated the weights to be more realistic for this example\n",
        "manual_weights = {'Vata': 3.0, 'Pitta': 3.0, 'Kapha': 3.0, 'vata+pitta': 0.5, 'pitta+kapha': 2.0, 'vata+kapha': 2.0}\n",
        "manual_rf = RandomForestClassifier(class_weight=manual_weights, random_state=42)\n",
        "print(\"\\nRandom Forest Classifier with manual class weights:\")\n",
        "print(manual_rf)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Load the csv file if you haven't already\n",
        "df = pd.read_csv('Prakriti_With_Features.csv')\n",
        "\n",
        "# Separate majority and minority classes\n",
        "df_majority = df[df.Dosha == 'vata+pitta']\n",
        "df_minority = df[df.Dosha != 'vata+pitta']\n",
        "\n",
        "# Downsample the majority class to match the size of the 'Vata' class\n",
        "df_majority_downsampled = resample(df_majority,\n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=len(df[df.Dosha == 'Vata']), # to match a minority class size\n",
        "                                 random_state=42)\n",
        "\n",
        "# Combine minority class DataFrame with downsampled majority class DataFrame\n",
        "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "print(\"Value counts after downsampling 'vata+pitta':\")\n",
        "print(df_downsampled.Dosha.value_counts())"
      ],
      "metadata": {
        "id": "QVBW23X5whmy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}