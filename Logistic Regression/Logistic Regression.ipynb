{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Analysis of Prakriti Dataset"
      ],
      "metadata": {
        "id": "RCScytZPsWuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "Y_v33CTHsgda"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcHteI9ZnIWi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"Prakriti_With_Features.csv\")\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the features\n",
        "X = pd.get_dummies(df.drop('Dosha', axis=1))\n",
        "\n",
        "# Binarize the target variable 'Dosha'\n",
        "y = df['Dosha'].apply(lambda x: 1 if x == 'Pitta' else 0)"
      ],
      "metadata": {
        "id": "7jnFyDNVssIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Splitting the Data"
      ],
      "metadata": {
        "id": "eLaWxZEjso1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
      ],
      "metadata": {
        "id": "o8NqEcTYsxFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model Development and Prediction"
      ],
      "metadata": {
        "id": "DleAh25XtZgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and fit the logistic regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = logreg.predict(X_test)\n",
        "print(\"Predicted Test Results: \", y_pred)"
      ],
      "metadata": {
        "id": "Dmn084Cnszv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Model Evaluation"
      ],
      "metadata": {
        "id": "BVEPIQUmtTo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix"
      ],
      "metadata": {
        "id": "7DQsxpgvtI4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate confusion matrix\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix using a heatmap\n",
        "class_names=['Not Pitta', 'Pitta'] # name of classes\n",
        "fig, ax = plt.subplots()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "# create heatmap\n",
        "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4NRNMUr-s3QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metrics"
      ],
      "metadata": {
        "id": "MGW9wqqttEvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print evaluation metrics\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "JkedAJbys6J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ROC Curve and AUC"
      ],
      "metadata": {
        "id": "8O8NaRLatAhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate ROC curve and AUC\n",
        "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
        "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UonTMyiCs7N6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}